{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda68474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderClassifier.from_hparams(source=\"speechbrain/lang-id-voxlingua107-ecapa\", savedir=\"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b411bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "\n",
    "# Iterate through the folder and save .wav filenames to a list\n",
    "wav_files = [file for file in os.listdir(DATA_DIR) if file.endswith('.wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wav_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb80027",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.txt', 'r') as f:\n",
    "    labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03abe65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e4ee23",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3352378936.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement this first\n",
    "def get_ground_truth_labels(wav_names: List[str]):\n",
    "  name_to_gt = {}\n",
    "  for wav_name in wav_names:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88d702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav = model.load_audio(\"/Users/tesnik/Desktop/Workspace/notebooks/spoken_language_identification/data/example_.wav\")\n",
    "# prediction =  model.classify_batch(signal)\n",
    "\n",
    "# emb =  model.encode_batch(signal)\n",
    "# print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mel_spectrogram(wav_file_path):\n",
    "  y, sr = librosa.load(wav_file_path, sr=None)\n",
    "\n",
    "  S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
    "\n",
    "  log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "  plt.figure(figsize=(10, 4))\n",
    "  librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel', cmap='coolwarm')\n",
    "  plt.title('Mel spectrogram')\n",
    "  plt.colorbar(format='%+02.0f dB')\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mel_spectrogram(f'data/{wav_files[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv39",
   "language": "python",
   "name": "venv39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
